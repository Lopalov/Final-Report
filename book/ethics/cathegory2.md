+++
# Ethics Category 2: Artificial Intelligence

While our current implementation does not include AI-powered features, we anticipate the possibility of integrating lightweight AI assistance in future iterations. Potential additions include grammar correction, auto-formatting, and inline content suggestions. These features could enhance the writing experience, especially for users with limited English proficiency or those working on repetitive formatting tasks. However, AI assistance in educational tools also brings several ethical concerns.

## Key Ethical Concerns

*   **Bias and Cultural Sensitivity** - Even in small features like grammar correction, AI systems may encode cultural or linguistic biases. These could favor particular academic styles or norms and exclude diverse contributors or non-native speakers.
*   **Transparency** - AI suggestions must be visibly distinct and non-intrusive. Users should be able to clearly identify and accept or reject AI-generated input, maintaining control over their own content.
*   **Accuracy** - AI may suggest incorrect changes, especially in technical or domain-specific content. This poses a risk in educational contexts, where users rely on content accuracy for learning.

## Risk Mitigation Strategies

To responsibly incorporate AI features in the future, the following measures should be considered:

*   **Visual Distinction** - All AI-generated suggestions will be clearly marked, similar to how GitHub Copilot indicates completions. This helps users understand which parts of their content are influenced by AI.
*   **Suggestions** - Rather than applying changes automatically, AI suggestions will be passive and require user approval, ensuring human oversight.
*   **Domain-Specific AI** - Any AI models or prompts will be tailored to educational and technical domains to minimize inappropriate or inaccurate suggestions.

These measures aim to responsibly enhance the editing experience while maintaining user autonomy and content integrity.